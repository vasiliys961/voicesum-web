# app.py - –£–ª—å—Ç—Ä–∞-–ª–µ–≥–∫–∞—è –≤–µ—Ä—Å–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
from flask import Flask, render_template, request, jsonify
import os
import tempfile
import whisper
from pydub import AudioSegment
from openai import OpenAI
import time
import logging
from httpx import Client as HttpxClient
import threading
import signal

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__, static_folder="static", template_folder="templates")
app.config['MAX_CONTENT_LENGTH'] = 10 * 1024 * 1024  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–æ 10 MB

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY")
TEMP_DIR = tempfile.mkdtemp(prefix="voicesum_")
os.makedirs(TEMP_DIR, exist_ok=True)

logger.info(f"üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–ø–∫–∞: {TEMP_DIR}")

# === –õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ===
whisper_model = None
llm_client = None

def load_whisper_model():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏"""
    global whisper_model
    if whisper_model is None:
        logger.info("üéôÔ∏è –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å Whisper (tiny)...")
        try:
            whisper_model = whisper.load_model("tiny", device="cpu")
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å Whisper (tiny) –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Whisper: {e}")
            raise
    return whisper_model

def load_llm_client():
    """–ó–∞–≥—Ä—É–∑–∫–∞ LLM –∫–ª–∏–µ–Ω—Ç–∞ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏"""
    global llm_client
    if llm_client is None and OPENROUTER_API_KEY:
        try:
            llm_client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=OPENROUTER_API_KEY,
                http_client=HttpxClient(proxies=None, timeout=20.0),
            )
            logger.info("‚úÖ OpenRouter –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ OpenRouter: {e}")
            raise
    return llm_client

# === –§—É–Ω–∫—Ü–∏–∏ —Å —Ç–∞–π–º–∞—É—Ç–æ–º ===

class TimeoutError(Exception):
    pass

def timeout_handler(signum, frame):
    raise TimeoutError("–û–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–≤—ã—Å–∏–ª–∞ —Ç–∞–π–º–∞—É—Ç")

def transcribe_with_timeout(wav_path, timeout_seconds=30):
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å —Ç–∞–π–º–∞—É—Ç–æ–º"""
    def transcribe_thread():
        nonlocal result, error
        try:
            model = load_whisper_model()
            result = model.transcribe(wav_path, language=None, fp16=False, verbose=False)
        except Exception as e:
            error = e

    result = None
    error = None
    
    thread = threading.Thread(target=transcribe_thread)
    thread.daemon = True
    thread.start()
    thread.join(timeout_seconds)
    
    if thread.is_alive():
        logger.error(f"‚ùå –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø—Ä–µ–≤—ã—Å–∏–ª–∞ —Ç–∞–π–º–∞—É—Ç {timeout_seconds}—Å")
        raise TimeoutError(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø—Ä–µ–≤—ã—Å–∏–ª–∞ {timeout_seconds} —Å–µ–∫—É–Ω–¥")
    
    if error:
        raise error
    
    if result:
        return result["text"].strip()
    
    raise Exception("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏")

def generate_summary_simple(text):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∑—é–º–µ"""
    try:
        client = load_llm_client()
        if not client:
            return "–†–µ–∑—é–º–µ: API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
        
        response = client.chat.completions.create(
            model="anthropic/claude-3-haiku",
            messages=[
                {"role": "system", "content": "–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –º–∞–∫—Å–∏–º—É–º 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."},
                {"role": "user", "content": f"–¢–µ–∫—Å—Ç: {text[:3000]}"}  # –ï—â–µ –º–µ–Ω—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤
            ],
            max_tokens=150,
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ–∑—é–º–µ: {e}")
        return f"–†–µ–∑—é–º–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ: {str(e)[:50]}"

# === –ú–∞—Ä—à—Ä—É—Ç—ã ===

@app.route("/")
def index():
    return render_template("index.html")

@app.route("/health")
def health():
    return jsonify({
        "status": "ok",
        "whisper_loaded": whisper_model is not None,
        "openrouter_configured": OPENROUTER_API_KEY is not None,
        "model": "tiny-lazy",
        "max_file_size": "10MB",
        "max_duration": "60s"
    })

@app.route("/transcribe", methods=["POST"])
def transcribe():
    start_time = time.time()
    input_path = None
    wav_path = None
    
    try:
        if 'audio' not in request.files:
            return jsonify({"error": "–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"}), 400

        file = request.files['audio']
        if file.filename == '':
            return jsonify({"error": "–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω"}), 400

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤
        timestamp = int(time.time() * 1000)
        input_path = os.path.join(TEMP_DIR, f"input_{timestamp}.tmp")
        wav_path = os.path.join(TEMP_DIR, f"converted_{timestamp}.wav")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        file.save(input_path)
        file_size = os.path.getsize(input_path)
        logger.info(f"üì• –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {file_size} –±–∞–π—Ç")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å –∂–µ—Å—Ç–∫–∏–º–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
        audio = AudioSegment.from_file(input_path)
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ - –º–∞–∫—Å–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥
        if len(audio) > 60000:  # 60 —Å–µ–∫—É–Ω–¥
            audio = audio[:60000]
            logger.info("‚è±Ô∏è –ê—É–¥–∏–æ –æ–±—Ä–µ–∑–∞–Ω–æ –¥–æ 60 —Å–µ–∫—É–Ω–¥")
        
        # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Å–∂–∞—Ç–∏–µ
        audio = audio.set_frame_rate(16000).set_channels(1)
        audio.export(wav_path, format="wav", parameters=["-ac", "1", "-ar", "16000"])
        
        logger.info(f"‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {time.time() - start_time:.1f}—Å")
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å —Ç–∞–π–º–∞—É—Ç–æ–º
        transcribe_start = time.time()
        transcript = transcribe_with_timeout(wav_path, timeout_seconds=25)
        
        logger.info(f"üéôÔ∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {time.time() - transcribe_start:.1f}—Å")
        
        if not transcript or len(transcript.strip()) < 3:
            return jsonify({"error": "–†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è"}), 400

        # –†–µ–∑—é–º–µ
        summary = generate_summary_simple(transcript)
        
        total_time = time.time() - start_time
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.1f}—Å")

        return jsonify({
            "transcript": transcript,
            "summary": summary,
            "model_used": "whisper-tiny",
            "processing_time": f"{total_time:.1f}s",
            "audio_duration": f"{len(audio)/1000:.1f}s"
        })
        
    except TimeoutError as e:
        logger.error(f"‚è∞ –¢–∞–π–º–∞—É—Ç: {e}")
        return jsonify({"error": f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–≤—ã—Å–∏–ª–∞ –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏: {e}"}), 408
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        return jsonify({"error": f"–û—à–∏–±–∫–∞: {str(e)[:100]}"}), 500
    finally:
        # –û—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
        for path in [input_path, wav_path]:
            if path and os.path.exists(path):
                try:
                    os.remove(path)
                except:
                    pass

# === –ó–∞–ø—É—Å–∫ ===
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    logger.info(f"‚úÖ –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É: {port}")
    app.run(host="0.0.0.0", port=port, debug=False, threaded=True)
