# app.py
from flask import Flask, render_template_string, request, jsonify
import os
import tempfile
import time
import logging
from pathlib import Path
import zipfile
import shutil
import wave
import json

from pydub import AudioSegment
import httpx
from openai import OpenAI

# ===== –õ–û–ì–ò =====
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("voicesum")

# ===== FLASK =====
app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 100 * 1024 * 1024  # 100 MB

# ===== –í–†–ï–ú–ï–ù–ù–ê–Ø –ü–ê–ü–ö–ê =====
TEMP_DIR = tempfile.mkdtemp(prefix="voicesum_")
os.makedirs(TEMP_DIR, exist_ok=True)
logger.info(f"üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–ø–∫–∞: {TEMP_DIR}")

# ===== –ö–õ–Æ–ß–ò / –ù–ê–°–¢–†–û–ô–ö–ò =====
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY", "")
if not OPENROUTER_API_KEY:
    logger.warning("‚ö†Ô∏è OPENROUTER_API_KEY –Ω–µ –∑–∞–¥–∞–Ω ‚Äî —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ –±—É–¥–µ—Ç.")

# ===== OpenRouter (—á–µ—Ä–µ–∑ OpenAI SDK) =====
llm_client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=OPENROUTER_API_KEY,
    timeout=30.0,
)

# ===== Vosk: —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ small-–º–æ–¥–µ–ª–∏ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è =====
VOSK_MODEL_URL = os.getenv(
    "VOSK_MODEL_URL",
    "https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip"
)
VOSK_DIR = Path(TEMP_DIR) / "vosk_model"
_vosk_ready = False
_asr_model = None

def ensure_vosk_model():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏ —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ—Ç Vosk-–º–æ–¥–µ–ª—å –≤ TEMP_DIR –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏."""
    if VOSK_DIR.exists() and any(VOSK_DIR.iterdir()):
        logger.info("‚úÖ –ú–æ–¥–µ–ª—å Vosk —É–∂–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–∞")
        return
    zip_path = Path(TEMP_DIR) / "vosk_model.zip"
    logger.info("‚¨áÔ∏è –°–∫–∞—á–∏–≤–∞–Ω–∏–µ Vosk-–º–æ–¥–µ–ª–∏‚Ä¶")
    with httpx.stream("GET", VOSK_MODEL_URL, timeout=300.0) as r:
        r.raise_for_status()
        with open(zip_path, "wb") as f:
            for chunk in r.iter_bytes():
                f.write(chunk)
    logger.info("üì¶ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ Vosk-–º–æ–¥–µ–ª–∏‚Ä¶")
    with zipfile.ZipFile(zip_path, "r") as z:
        root = z.namelist()[0].split("/")[0]
        z.extractall(TEMP_DIR)
    extracted = Path(TEMP_DIR) / root
    if VOSK_DIR.exists():
        shutil.rmtree(VOSK_DIR)
    extracted.rename(VOSK_DIR)
    zip_path.unlink(missing_ok=True)
    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞: {VOSK_DIR}")

def init_vosk():
    """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Vosk-–º–æ–¥–µ–ª–∏."""
    global _vosk_ready, _asr_model
    if _vosk_ready:
        return
    ensure_vosk_model()
    from vosk import Model
    _asr_model = Model(str(VOSK_DIR))
    _vosk_ready = True
    logger.info("üß† Vosk –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

# ===== –£–¢–ò–õ–ò–¢–´ –ê–£–î–ò–û =====
def convert_to_wav(input_path: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –ª—é–±–æ–≥–æ –∞—É–¥–∏–æ ‚Üí WAV 16 kHz mono."""
    audio = AudioSegment.from_file(input_path)
    audio = audio.set_frame_rate(16000).set_channels(1)
    wav_path = os.path.join(TEMP_DIR, f"{int(time.time()*1000)}.wav")
    audio.export(wav_path, format="wav")
    return wav_path

def transcribe_vosk(wav_path: str) -> str:
    """–û—Ñ—Ñ–ª–∞–π–Ω ASR —á–µ—Ä–µ–∑ Vosk small."""
    init_vosk()
    from vosk import KaldiRecognizer
    wf = wave.open(wav_path, "rb")
    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() not in (8000, 16000):
        raise RuntimeError("WAV –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å PCM 16-bit mono 8/16 kHz (—ç—Ç–æ –¥–µ–ª–∞–µ—Ç convert_to_wav)")
    rec = KaldiRecognizer(_asr_model, wf.getframerate())
    rec.SetWords(True)
    parts = []
    while True:
        data = wf.readframes(4000)
        if not data:
            break
        if rec.AcceptWaveform(data):
            res = json.loads(rec.Result())
            if "text" in res:
                parts.append(res["text"])
    final = json.loads(rec.FinalResult())
    if "text" in final:
        parts.append(final["text"])
    return " ".join(t for t in parts if t).strip()

# ===== –†–ï–ó–Æ–ú–ï (LLM) =====
from textwrap import dedent

def generate_summary(text: str) -> str:
    if not OPENROUTER_API_KEY:
        return "–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: –Ω–µ –∑–∞–¥–∞–Ω OPENROUTER_API_KEY."

    prompt = dedent(f"""\
        –¢—ã ‚Äî –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –í—ã–¥–∞–π —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
        –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ: <1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è>
        ‚Äî –†–µ—à–µ–Ω–∏—è: <–∫—Ä–∞—Ç–∫–æ>
        ‚Äî –î–µ–π—Å—Ç–≤–∏—è: <–∫—Ä–∞—Ç–∫–æ>
        ‚Äî –î–æ–≥–æ–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç–∏: <–∫—Ä–∞—Ç–∫–æ>
        ‚Äî –¢–µ–º—ã: <–∫—Ä–∞—Ç–∫–æ>

        –†–∞–∑–≥–æ–≤–æ—Ä:

        {text[:12000]}
    """)

    r = llm_client.chat.completions.create(
        model="anthropic/claude-3-haiku",
        messages=[
            {"role": "system", "content": "–¢—ã ‚Äî –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=500,
        temperature=0.2,
    )
    return r.choices[0].message.content.strip()

# ===== UI =====
INDEX_HTML = """
<!doctype html><html lang="ru"><meta charset="utf-8">
<title>VoiceSum</title>
<h1>–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∞—É–¥–∏–æ ‚Üí —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (Vosk) ‚Üí —Ä–µ–∑—é–º–µ (OpenRouter)</h1>
<form method="POST" action="/transcribe" enctype="multipart/form-data">
  <input type="file" name="audio" accept="audio/*" required>
  <button type="submit">–û—Ç–ø—Ä–∞–≤–∏—Ç—å</button>
</form>
"""

@app.route("/", methods=["GET"])
def index():
    return render_template_string(INDEX_HTML)

@app.route("/transcribe", methods=["POST"])
def transcribe():
    if 'audio' not in request.files:
        return jsonify({"error": "–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"}), 400
    f = request.files['audio']
    if not f.filename:
        return jsonify({"error": "–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω"}), 400

    src = os.path.join(TEMP_DIR, f.filename)
    try:
        f.save(src)
        wav = convert_to_wav(src)
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")
        return jsonify({"error": f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}"}), 500
    finally:
        try:
            if os.path.exists(src):
                os.remove(src)
        except:
            pass

    try:
        transcript = transcribe_vosk(wav)
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏")
        transcript = f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}"
    finally:
        try:
            if os.path.exists(wav):
                os.remove(wav)
        except:
            pass

    try:
        summary = generate_summary(transcript if transcript else "–ü—É—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è.")
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏")
        summary = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∑—é–º–µ: {e}"

    return jsonify({"transcript": transcript, "summary": summary})

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port, debug=False)

